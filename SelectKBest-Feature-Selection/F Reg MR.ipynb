{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8933d86f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T06:20:14.658238Z",
     "start_time": "2022-03-29T06:20:14.097532Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filter = \"plant.id=='<plant-id>' && hotMeasurements.doNotNormalize != true\"\n",
    "# tags = ['CD6:602PT038.PV','CD6:602PT047.PV','CD6:602PT073.PV']\n",
    "# filter = c3.Filter().intersects(\"id\",tags)\n",
    "priority = 100\n",
    "batchSize = 100\n",
    "include = \"id, plant.id\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be9d96",
   "metadata": {},
   "source": [
    "### TAGS experimented:  \n",
    "- `ModelId` -> Tag_name || Training Period for that Model ID \n",
    "    1. **`77a43528-4161-47cc-b3d7-834afd02fc06` -> CD6:602PC037.PV || 24 Jul '16 - 24 Jul '17**\n",
    "    2. **`bf0ba412-9dc3-4d27-97e4-6e81f24fc343` -> CD6:602TT108.PV || 01 Feb '17 - 01 Feb '18**\n",
    "    3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526a6ce0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T06:20:16.310661Z",
     "start_time": "2022-03-29T06:20:16.297858Z"
    }
   },
   "outputs": [],
   "source": [
    "def mapper(batch, objs, job):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.feature_selection import SelectKBest, chi2, f_regression, mutual_info_regression\n",
    "    from scipy import stats\n",
    "    from scipy.stats.stats import pearsonr\n",
    "    \n",
    "    #get prediction target data\n",
    "    modelId = \"bf0ba412-9dc3-4d27-97e4-6e81f24fc343\"\n",
    "    start=\"2017-02-01T00:00:00.000\"\n",
    "    end=\"2018-02-01T00:00:00.000\"\n",
    "    interval=\"MINUTE\"\n",
    "    # Fetching Target Tag Name\n",
    "    predictionTargetId = c3.ValveTagModel.get(modelId, \"predictionTarget.id\").predictionTarget.id\n",
    "    # Fetching Feature Tag names\n",
    "    ids = list(map(lambda x:x.id, objs))\n",
    "    \n",
    "    predTargetMeasurements = c3.ValveTagModel.evalMetrics(spec={\n",
    "        \"ids\":[modelId],\n",
    "        \"expressions\": [\"TagMeasurementsExclusionsRemoved\"],\n",
    "        \"start\":start,\n",
    "        \"end\":end,\n",
    "        \"interval\":interval,\n",
    "        \"include\":\"data, missing\"\n",
    "    })\n",
    "    \n",
    "    if predTargetMeasurements is not None and predTargetMeasurements.result is not None:\n",
    "        predTargetMeasurements = predTargetMeasurements.result.toJson()\n",
    "    else:\n",
    "        predTargetMeasurements = {}\n",
    "    \n",
    "    #get tag data\n",
    "    comparison_tag_metrics = c3.PiTag.evalMetrics(spec={\n",
    "        \"ids\":ids,\n",
    "        \"expressions\":[\"TagMeasurements\"],\n",
    "        \"start\":start,\n",
    "        \"end\":end,\n",
    "        \"interval\":interval\n",
    "    })\n",
    "    \n",
    "    if comparison_tag_metrics is not None and comparison_tag_metrics.result is not None:\n",
    "        comparison_tag_metrics = comparison_tag_metrics.result.toJson()\n",
    "    else:\n",
    "        comparison_tag_metrics = {}\n",
    "    \n",
    "    tag_data_target = None\n",
    "    if 'm_data' in predTargetMeasurements.get(modelId, {}).get('TagMeasurementsExclusionsRemoved', {}):\n",
    "        tag_data_target = predTargetMeasurements[modelId]['TagMeasurementsExclusionsRemoved']['m_data']\n",
    "\n",
    "    # feature dataframe being populated | Started from Numpy array to dataframe\n",
    "    tag_data_feature = np.empty((len(tag_data_target), len(ids)), dtype=np.float32, order='f')\n",
    "    \n",
    "    # To convert the c3 Obtained data to DataFrame\n",
    "    for i, obj_id in enumerate(ids):\n",
    "        if 'm_data' in comparison_tag_metrics.get(obj_id, {}).get(\"TagMeasurements\", {}):\n",
    "            # Using float32 to reduce the memory footprint and better performance,\n",
    "            # Comparison_tag_metrics need to be modified as well, otherwise it populate the tag_data\n",
    "            # with the float64\n",
    "            tag_data_feature[:, i] = np.array(comparison_tag_metrics[obj_id][\"TagMeasurements\"]['m_data']).astype(np.float32,\n",
    "                                                                                                          copy=False)\n",
    "        else:\n",
    "            tag_data_feature[:, i] = np.nan\n",
    "\n",
    "   \n",
    "    feature_df = pd.DataFrame(tag_data_feature,columns = ids)\n",
    "    # Since we know, we already have TARGET DATAPOINTS in a numpy aaray, we directly converted it to dataframe!\n",
    "    pred_df = pd.DataFrame(tag_data_target,columns=[predictionTargetId])\n",
    "    \n",
    "    # Running SelectKBest\n",
    "    \n",
    "    # Converting values in Array format for execution\n",
    "    features = feature_df.values\n",
    "    target = target_df.values.ravel()\n",
    "    target = target.astype('int')\n",
    "\n",
    "    # Running SelectKBest\n",
    "    test = SelectKBest(score_func = f_regression, k=batch)\n",
    "    fit = test.fit(features,target)\n",
    "    feature_scores = fit.scores_[fit.get_support()]\n",
    "\n",
    "\n",
    "    mask = test.get_support()\n",
    "    new_features = feature_df.columns[mask]\n",
    "    prep_df = pd.DataFrame()\n",
    "    prep_df['Columns'] = feature_df.columns\n",
    "    prep_df['{}_scores'.format(scoring_function.__name__)] = fit.scores_\n",
    "    prep_df['P_values'] = fit.pvalues_\n",
    "    out_list = []\n",
    "    for column in feature_df.columns:\n",
    "        corr_tuple = pearsonr(feature_df[column], target)\n",
    "        out_list.append(corr_tuple[0])\n",
    "\n",
    "    prep_df['Correlation_scores'] = out_list\n",
    "    \n",
    "#     def select_k_best(feature_df,pred_df,batch):\n",
    "#         #feature_dataframe = feature_df.set_index('timestamp')\n",
    "#         #target_dataframe = pred_df.set_index('timestamp')\n",
    "        \n",
    "#         # Converting values in Array format for execution\n",
    "#         features = feature_df.values\n",
    "#         target = target_df.values.ravel()\n",
    "#         target = target.astype('int')\n",
    "        \n",
    "#         # Running SelectKBest\n",
    "#         test = SelectKBest(score_func = f_regression, k=batch)\n",
    "#         fit = test.fit(features,target)\n",
    "#         feature_scores = fit.scores_[fit.get_support()]\n",
    "\n",
    "\n",
    "#         mask = test.get_support()\n",
    "#         new_features = feature_df.columns[mask]\n",
    "#         prep_df = pd.DataFrame()\n",
    "#         prep_df['Columns'] = feature_df.columns\n",
    "#         prep_df['{}_scores'.format(scoring_function.__name__)] = fit.scores_\n",
    "#         prep_df['P_values'] = fit.pvalues_\n",
    "#         out_list = []\n",
    "#         for column in feature_df.columns:\n",
    "#             corr_tuple = pearsonr(feature_df[column], target)\n",
    "#             out_list.append(corr_tuple[0])\n",
    "        \n",
    "#         prep_df['Correlation_scores'] = out_list\n",
    "\n",
    "#         return new_features,target,prep_df\n",
    "\n",
    "#     # Executing SelectKBest F-Regression scoring function\n",
    "#     f_reg_res_df = select_k_best(feature_df,pred_df,batch)\n",
    "    \n",
    "#     fileName = 'features.csv'\n",
    "#     url = c3.FileSystem.inst().urlFromEncodedPath(c3.FileSystem.inst().rootUrl() + \"/extract/f_regression/\" + fileName)\n",
    "#     file = c3.FileSystem.inst().makeFile(url, \"text/csv\")\n",
    "#     file.writeString(feature_df.to_csv())\n",
    "    \n",
    "\n",
    "#     fileName = 'target.csv'\n",
    "#     url = c3.FileSystem.inst().urlFromEncodedPath(c3.FileSystem.inst().rootUrl() + \"/extract/f_regression/\" + fileName)\n",
    "#     file = c3.FileSystem.inst().makeFile(url, \"text/csv\")\n",
    "#     file.writeString(pred_df.to_csv())\n",
    "\n",
    "\n",
    "    \n",
    "    # Storing the result in a CSV @ Azure Blob\n",
    "    fileName = 'f_regression_result.csv'\n",
    "    url = c3.FileSystem.inst().urlFromEncodedPath(c3.FileSystem.inst().rootUrl() + \"/extract/f_regression/\" + fileName)\n",
    "    file = c3.FileSystem.inst().makeFile(url, \"text/csv\")\n",
    "    file.writeString(prep_df.to_csv())\n",
    "\n",
    "          \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81cdaed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T06:20:17.774235Z",
     "start_time": "2022-03-29T06:20:16.903438Z"
    }
   },
   "outputs": [],
   "source": [
    "job = c3.DynMapReduce.startFromSpec(c3.DynMapReduceSpec(\n",
    "   targetType=\"PiTag\",\n",
    "   filter=filter,\n",
    "   priority=priority,\n",
    "   include=include,\n",
    "   batchSize=batchSize,\n",
    "   mapLambda=c3.Lambda.fromPython(mapper, runtime=\"sklearn_3_0_0\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef7b3f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T06:20:38.333109Z",
     "start_time": "2022-03-29T06:20:38.293192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c3.MapReduceStatus(\n",
       " started=datetime.datetime(2022, 3, 29, 6, 20, 18, tzinfo=datetime.timezone.utc),\n",
       " startedby='atul.mishra@shell.com',\n",
       " completed=datetime.datetime(2022, 3, 29, 6, 20, 38, tzinfo=datetime.timezone.utc),\n",
       " status='completed')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a85eac",
   "metadata": {},
   "source": [
    "##### TO check the Job status in CONSOLE:\n",
    "- **`c3Grid(InvalidationQueue.countAll(\"type\"));`**\n",
    "- **`c3Grid(DynMapReduce.fetch({order: \"descending(meta.created)\",limit:5}))`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626521f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85798a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "has_local_update": false,
  "is_local": true,
  "is_remote": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "last_sync_time": "2022-03-29T06:30:45.226094"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
